{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ceb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data.load_data import *\n",
    "from processing.utils import *\n",
    "from NotezartTransformer import NotezartTransformer\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "seed = 2022\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "checkpoint_path = Path('resource/gen4/v2').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6586fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a midi file as an array of events\n",
    "def read_midi(midi_path):\n",
    "    note_items, tempo_items = read_items(midi_path)\n",
    "    note_items = quantize_items(note_items)\n",
    "    max_time = note_items[-1].end\n",
    "    chord_items = extract_chords(note_items)\n",
    "    items = chord_items + tempo_items + note_items\n",
    "    groups = group_items(items, max_time)\n",
    "    events = item2event(groups)\n",
    "    return np.array(events, dtype=object)\n",
    "\n",
    "# read in a series of midi files as a list of sequence of events\n",
    "def transform_midi(midi_paths):\n",
    "    # extract events\n",
    "    events = []\n",
    "    all_events = []\n",
    "    for path in midi_paths:\n",
    "        try:\n",
    "            midi = read_midi(path)\n",
    "            events.append(np.asarray([e.to_key() for e in midi]))\n",
    "            all_events.append(midi)\n",
    "        except:\n",
    "            print(f\"Failed: {path}\")\n",
    "    return all_events, np.asarray(events, dtype=object)\n",
    "\n",
    "def build_lookup(midi_paths, dictionary_path):\n",
    "    all_events, events = transform_midi(midi_paths=midi_paths)\n",
    "\n",
    "    unique_events = np.unique([e for s in events for e in s])\n",
    "    event2word = dict(zip(unique_events, list(range(0, len(unique_events)))))\n",
    "    word2event = {i: e for e, i in event2word.items()}\n",
    "\n",
    "    with open(dictionary_path, 'wb') as handle:\n",
    "        pickle.dump([event2word, word2event], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "      \n",
    "    return all_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ed2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataset_name):\n",
    "    print(\"Loading data...\")\n",
    "    dictionary_path = f\"{checkpoint_path}/dictionary/dictionary.pkl\"\n",
    "    midi_paths = get_all_files(dataset_name=dataset_name)\n",
    "\n",
    "    # Build lookup dictionaries\n",
    "    all_events = build_lookup(midi_paths=midi_paths, dictionary_path=dictionary_path)\n",
    "    model = NotezartTransformer(checkpoint=checkpoint_path, is_training=True)\n",
    "    model.load_model()\n",
    "\n",
    "    training_set_path = f\"{checkpoint_path}/data/training_set.pkl\"\n",
    "\n",
    "    def get_data(training_set_path):\n",
    "        training_data = model.prepare_data(all_events=all_events)\n",
    "\n",
    "        with open(training_set_path, 'wb') as handle:\n",
    "            pickle.dump(training_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        return training_data\n",
    "\n",
    "    training_data = get_data(training_set_path)\n",
    "\n",
    "    output_checkpoint_folder = f\"{checkpoint_path}/model\" # your decision\n",
    "    model.finetune(epochs=100, training_data=training_data, output_checkpoint_folder=output_checkpoint_folder)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3366348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NotezartTransformer import NotezartTransformer\n",
    "\n",
    "#model = NotezartTransformer(checkpoint=checkpoint_path, is_training=True)\n",
    "#model.load_model()\n",
    "\n",
    "model = NotezartTransformer(checkpoint=checkpoint_path, is_training=False)\n",
    "model.load_model(existing_model=f\"{checkpoint_path}/checkpoints/model-027\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_path = f\"{checkpoint_path}/data/training_set.pkl\"\n",
    "\n",
    "def get_data(training_set_path):\n",
    "    training_data = model.prepare_data(midi_paths)\n",
    "\n",
    "    with open(training_set_path, 'wb') as handle:\n",
    "        pickle.dump(training_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return training_data\n",
    "\n",
    "training_data = get_data(training_set_path)\n",
    "training_data = pickle.load(open(training_set_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_checkpoint_folder = f\"{checkpoint_path}/checkpoints\" # your decision\n",
    "\n",
    "#model.finetune(epochs=100, training_data=training_data, output_checkpoint_folder=output_checkpoint_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb97a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate(\n",
    "        n_target_bar=20,\n",
    "        temperature=1.2,\n",
    "        topk=5,\n",
    "        output_path=f\"{checkpoint_path}/output/sample.midi\",\n",
    "        prompt=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
