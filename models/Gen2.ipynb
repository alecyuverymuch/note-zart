{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ceb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data.load_data import *\n",
    "from processing.utils import *\n",
    "\n",
    "#print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "seed = 2022\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(midi_path):\n",
    "    note_items, tempo_items = read_items(midi_path)\n",
    "    note_items = quantize_items(note_items)\n",
    "    max_time = note_items[-1].end\n",
    "    chord_items = extract_chords(note_items)\n",
    "    items = chord_items + tempo_items + note_items\n",
    "    groups = group_items(items, max_time)\n",
    "    return item2event(groups)\n",
    "\n",
    "def transform_midi(midi_paths):\n",
    "    # extract events\n",
    "    all_events = []\n",
    "    for path in midi_paths:\n",
    "        events = read_midi(path)\n",
    "        for event in events:\n",
    "            all_events.append(event)\n",
    "    return np.array(all_events, dtype=object)\n",
    "\n",
    "def transform_midi_alt(midi_paths):\n",
    "    # extract events\n",
    "    all_events = []\n",
    "    for path in midi_paths:\n",
    "        events = read_midi(path)\n",
    "        for event in events:\n",
    "            all_events.append(event)\n",
    "    return pd.DataFrame.from_records([e.to_dict() for e in all_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\")\n",
    "midi_paths = get_all_files(dataset_name=\"MOZART_SMALL\")\n",
    "dataset = transform_midi(midi_paths=midi_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating tensorflow dataset...\")\n",
    "notes_dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
    "print(f\">> {notes_dataset.element_spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef04127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(dataset: tf.data.Dataset, seq_length: int, vocab_size=128) -> tf.data.Dataset:\n",
    "    \"\"\" Returns TF Dataset of sequence and label examples \"\"\"\n",
    "    seq_length = seq_length + 1\n",
    "\n",
    "    # Take 1 extra for the labels\n",
    "    windows = dataset.window(seq_length, shift=1, stride=1, drop_remainder=True)\n",
    "\n",
    "    # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "    flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "    sequences = windows.flat_map(flatten)\n",
    "\n",
    "    # Normalize note pitch\n",
    "    def scale_pitch(x):\n",
    "        return x / vocab_size\n",
    "\n",
    "    # Split the labels\n",
    "    def split_labels(sequences):\n",
    "        inputs = sequences[:-1]\n",
    "        labels_dense = sequences[-1]\n",
    "        labels = {key: labels_dense[i] for i, key in enumerate([\"pitch\"])}\n",
    "\n",
    "        return scale_pitch(inputs), labels\n",
    "\n",
    "    return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "seq_length = 64\n",
    "vocab_size = 128  # range of pitches supported in pretty_midi\n",
    "sequence_dataset = create_sequences(notes_dataset, seq_length, vocab_size)\n",
    "print(sequence_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq, target in sequence_dataset.take(1):\n",
    "    print('sequence shape:', seq.shape)\n",
    "    print('sequence elements (first 5):', seq[0: 5])\n",
    "    print('target:', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74205a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "buffer_size = note_count - seq_length  # the number of items in the dataset\n",
    "train_dataset = (sequence_dataset\n",
    "                 .shuffle(buffer_size)\n",
    "                 .batch(batch_size, drop_remainder=True)\n",
    "                 .cache()\n",
    "                 .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (seq_length, 1)\n",
    "learning_rate = 0.005\n",
    "\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "x = tf.keras.layers.LSTM(512)(inputs)\n",
    "x = tf.keras.layers.Dense(1024)(x)\n",
    "\n",
    "outputs = {\n",
    "    \"pitch\": tf.keras.layers.Dense(128, name=\"pitch\")(x)\n",
    "}\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "loss = {\n",
    "    \"pitch\": tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "}\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1a50f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da461c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./training_checkpoints/ckpt_{epoch}\",\n",
    "        save_weights_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88738d2f",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ce719",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6af21",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_next_note(notes: np.ndarray, model: tf.keras.Model, temperature=1.0) -> int:\n",
    "    \"\"\"Generates a note IDs using a trained sequence model.\"\"\"\n",
    "    assert temperature > 0\n",
    "    # Add batch dimension\n",
    "    inputs = tf.expand_dims(notes, 0)\n",
    "    predictions = model.predict(inputs)\n",
    "    pitch_logits = predictions['pitch']\n",
    "    pitch_logits /= temperature\n",
    "    pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
    "    pitch = tf.squeeze(pitch, axis=-1)\n",
    "    return int(pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7fec3c",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temperature = 3.0\n",
    "num_predictions = 500\n",
    "\n",
    "a = random.randint(0, 6000)\n",
    "print(f\"Using starter notes from {a} to {a + 64}...\")\n",
    "sample_notes = np.stack(dataset[a:a + 64])\n",
    "input_notes = (sample_notes[:seq_length] / np.array([vocab_size]))\n",
    "\n",
    "generated_notes = []\n",
    "prev_start = 0\n",
    "for _ in range(num_predictions):\n",
    "    pitch = predict_next_note(input_notes, model, temperature)\n",
    "    start = prev_start + 0.1\n",
    "    end = start + random.random()\n",
    "    input_note = (pitch,)\n",
    "    generated_notes.append((*input_note, start, end))\n",
    "    input_notes = np.delete(input_notes, 0, axis=0)\n",
    "    input_notes = np.append(input_notes, np.expand_dims(input_note, axis=0), axis=0)\n",
    "    prev_start = start\n",
    "\n",
    "generated_notes = pd.DataFrame(generated_notes, columns=(\"pitch\", \"start\", \"end\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e647c611",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def notes_to_midi(notes: pd.DataFrame, out_file: str, instrument_name=\"Acoustic Grand Piano\") -> pretty_midi.PrettyMIDI:\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=pretty_midi.instrument_name_to_program(instrument_name))\n",
    "\n",
    "    for i, note in notes.iterrows():\n",
    "        print(note)\n",
    "        n = pretty_midi.Note(\n",
    "            velocity=random.randint(80, 120),\n",
    "            pitch=int(note[\"pitch\"]),\n",
    "            start=note[\"start\"],\n",
    "            end=note[\"end\"],\n",
    "        )\n",
    "        instrument.notes.append(n)\n",
    "\n",
    "    pm.instruments.append(instrument)\n",
    "    pm.write(out_file)\n",
    "    return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93288f8a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out_file = f\"../output/{int(time.time())}.mid\"\n",
    "out_pm = notes_to_midi(generated_notes, out_file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc20b2",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_piano_roll(notes: pd.DataFrame, count=None):\n",
    "    if count:\n",
    "        title = f'First {count} notes'\n",
    "    else:\n",
    "        title = f'Whole track'\n",
    "        count = len(notes['pitch'])\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
    "    plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
    "    plt.plot(\n",
    "        plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Pitch')\n",
    "    _ = plt.title(title)\n",
    "\n",
    "\n",
    "plot_piano_roll(generated_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51546f3b",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
