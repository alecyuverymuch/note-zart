{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05ceb0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from data.load_data import *\n",
    "from processing.utils import *\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "seed = 2022\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6586fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a midi file as an array of events\n",
    "def read_midi(midi_path):\n",
    "    note_items, tempo_items = read_items(midi_path)\n",
    "    note_items = quantize_items(note_items)\n",
    "    max_time = note_items[-1].end\n",
    "    chord_items = extract_chords(note_items)\n",
    "    items = chord_items + tempo_items + note_items\n",
    "    groups = group_items(items, max_time)\n",
    "    events = item2event(groups)\n",
    "    return np.array(events, dtype=object)\n",
    "\n",
    "# read in a series of midi files as a list of sequence of events\n",
    "def transform_midi(midi_paths):\n",
    "    events = []\n",
    "    for path in midi_paths:\n",
    "        events.append(read_midi(path))\n",
    "    return np.asarray(events, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374c5424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      ">> (21,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "midi_paths = get_all_files(dataset_name=\"MOZART_SMALL\")\n",
    "dataset = transform_midi(midi_paths=midi_paths)\n",
    "print(f\">> {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "382cbeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Event(name=Bar, time=None, value=None, text=1),\n",
       "       Event(name=Position, time=0, value=1/16, text=0),\n",
       "       Event(name=Chord, time=0, value=A#:maj, text=A#:maj),\n",
       "       Event(name=Position, time=0, value=1/16, text=0),\n",
       "       Event(name=Tempo Class, time=0, value=fast, text=None),\n",
       "       Event(name=Tempo Value, time=0, value=10, text=None),\n",
       "       Event(name=Position, time=0, value=1/16, text=0),\n",
       "       Event(name=Note Velocity, time=0, value=12, text=50/48),\n",
       "       Event(name=Note On, time=0, value=70, text=70),\n",
       "       Event(name=Note Duration, time=0, value=15, text=960/960)],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b175d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRUCTURE BASED DATA\n",
    "# Group events into a series of event structures:\n",
    "# Structure 1: Bar\n",
    "# Structure 2: Position, Note Velocity, Note On, Note Duration\n",
    "# Strucutre 3: Position, Chord\n",
    "# Structure 4: Position, Tempo Class, Tempo Value\n",
    "event_structs = []\n",
    "\n",
    "for e in dataset:\n",
    "    event_struct = []\n",
    "\n",
    "    for i in range(len(e)-3):\n",
    "        if e[i].name == 'Bar' and i > 0:\n",
    "            bar = Event(e[i].name, None, e[i].value, None)\n",
    "            event_struct.append(tuple([e[i]]))\n",
    "        elif e[i].name == 'Position' and \\\n",
    "            e[i+1].name == 'Note Velocity' and \\\n",
    "            e[i+2].name == 'Note On' and \\\n",
    "            e[i+3].name == 'Note Duration':\n",
    "            position = Event(e[i].name, None, e[i].value, None)\n",
    "            velocity = Event(e[i+1].name, None, e[i+1].value, None)\n",
    "            pitch = Event(e[i+2].name, None, e[i+2].value, None)\n",
    "            duration = Event(e[i+3].name, None, e[i+3].value, None)\n",
    "            event_struct.append(tuple([e[i], e[i+1], e[i+2], e[i+3]]))\n",
    "        elif e[i].name == 'Position' and e[i+1].name == 'Chord':\n",
    "            position = Event(e[i].name, None, e[i].value, None)\n",
    "            chord = Event(e[i+1].name, None, e[i+1].value, None)\n",
    "            event_struct.append(tuple([e[i], e[i+1]]))\n",
    "        elif e[i].name == 'Position' and \\\n",
    "            e[i+1].name == 'Tempo Class' and \\\n",
    "            e[i+2].name == 'Tempo Value':\n",
    "            position = Event(e[i].name, None, e[i].value, None)\n",
    "            t_class = Event(e[i+1].name, None, e[i+1].value, None)\n",
    "            t_value = Event(e[i+2].name, None, e[i+2].value, None)\n",
    "            event_struct.append(tuple([e[i], e[i+1], e[i+2]]))\n",
    "\n",
    "    event_structs.append(np.asarray(event_struct, dtype=object))\n",
    "\n",
    "event_structs = np.asarray(event_structs, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2091950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Event Structures: 60750\n",
      "Unique Event Structures: 55983\n"
     ]
    }
   ],
   "source": [
    "# Encode all event structures as a indices and build a lookup table\n",
    "all_event_structs = np.asarray(np.concatenate(event_structs), dtype=object).flat\n",
    "print(f\"All Event Structures: {len(all_event_structs)}\")\n",
    "\n",
    "_, indices = np.unique([s for s in all_event_structs], return_index=True)\n",
    "unique_event_structs = np.asanyarray([all_event_structs[i] for i in indices], dtype=object)\n",
    "print(f\"Unique Event Structures: {len(unique_event_structs)}\")\n",
    "\n",
    "struct2int = dict(zip(unique_event_structs, list(range(0, len(unique_event_structs)))))\n",
    "int2struct = {i: e for e, i in struct2int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cbf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training sequences of length 64\n",
    "# Define a list of targets which is the event struture that follows the training sequence\n",
    "sequenceLength = 64\n",
    "\n",
    "train_structs = []\n",
    "target_structs = []\n",
    "for i in range(len(event_structs)):\n",
    "    struct_list = [struct2int[s] for s in event_structs[i]]\n",
    "    for i in range(len(struct_list) - sequenceLength):\n",
    "        train_structs.append(struct_list[i:i+sequenceLength])\n",
    "        target_structs.append(struct_list[i+1])\n",
    "\n",
    "train_structs = np.asarray(train_structs, dtype=int64)[:4096,:]\n",
    "target_structs = np.asarray(target_structs)[:4096]\n",
    "\n",
    "train_structs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5123b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 64)]           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1, 512)            1181696   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 256)            131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 55983)          14387631  \n",
      "=================================================================\n",
      "Total params: 15,700,655\n",
      "Trainable params: 15,700,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# SET BASED DATA\n",
    "\n",
    "# Define input layers\n",
    "struct_input = tf.keras.layers.Input(shape = (1, train_structs.shape[1]))\n",
    "\n",
    "# Define LSTM layer\n",
    "lstm_layer = tf.keras.layers.LSTM(512, return_sequences=True)(struct_input)\n",
    "\n",
    "# Define dense layer\n",
    "dense_layer = tf.keras.layers.Dense(256)(lstm_layer)\n",
    "\n",
    "# Define output layers\n",
    "struct_output = tf.keras.layers.Dense(len(unique_event_structs), activation = 'softmax')(dense_layer)\n",
    "\n",
    "# Define model\n",
    "lstm = tf.keras.Model(inputs = struct_input, outputs = struct_output)\n",
    "\n",
    "# Compile the model\n",
    "lstm.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "lstm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dd2ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4096 samples\n",
      "Epoch 1/100\n",
      "4096/4096 [==============================] - 34s 8ms/sample - loss: 10.9411\n",
      "Epoch 2/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 9.6849\n",
      "Epoch 3/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.8895\n",
      "Epoch 4/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.6746\n",
      "Epoch 5/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.5613\n",
      "Epoch 6/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.4785\n",
      "Epoch 7/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.4037\n",
      "Epoch 8/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.3487\n",
      "Epoch 9/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.3018\n",
      "Epoch 10/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.2566\n",
      "Epoch 11/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 8.2114\n",
      "Epoch 12/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 8.1692\n",
      "Epoch 13/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 8.1276\n",
      "Epoch 14/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 8.0859\n",
      "Epoch 15/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 8.0460\n",
      "Epoch 16/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 8.0060\n",
      "Epoch 17/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.9690\n",
      "Epoch 18/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.9282\n",
      "Epoch 19/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.8934\n",
      "Epoch 20/100\n",
      "4096/4096 [==============================] - 34s 8ms/sample - loss: 7.8553\n",
      "Epoch 21/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.8261\n",
      "Epoch 22/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.7920\n",
      "Epoch 23/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.7650\n",
      "Epoch 24/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.7354\n",
      "Epoch 25/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.7066\n",
      "Epoch 26/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.6785\n",
      "Epoch 27/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.6546\n",
      "Epoch 28/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.6309\n",
      "Epoch 29/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.6105\n",
      "Epoch 30/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.5916\n",
      "Epoch 31/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.5656\n",
      "Epoch 32/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.5472\n",
      "Epoch 33/100\n",
      "4096/4096 [==============================] - 34s 8ms/sample - loss: 7.5269\n",
      "Epoch 34/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.5086\n",
      "Epoch 35/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.4925\n",
      "Epoch 36/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.4756\n",
      "Epoch 37/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.4604\n",
      "Epoch 38/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.4460\n",
      "Epoch 39/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.4343\n",
      "Epoch 40/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.4198\n",
      "Epoch 41/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.4078\n",
      "Epoch 42/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3931\n",
      "Epoch 43/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.3794\n",
      "Epoch 44/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3709\n",
      "Epoch 45/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.3578\n",
      "Epoch 46/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3511\n",
      "Epoch 47/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3409\n",
      "Epoch 48/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3325\n",
      "Epoch 49/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3260\n",
      "Epoch 50/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3165\n",
      "Epoch 51/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3089\n",
      "Epoch 52/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.3014\n",
      "Epoch 53/100\n",
      "4096/4096 [==============================] - 45s 11ms/sample - loss: 7.2935\n",
      "Epoch 54/100\n",
      "4096/4096 [==============================] - 166s 41ms/sample - loss: 7.2826\n",
      "Epoch 55/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.2775\n",
      "Epoch 56/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.2708\n",
      "Epoch 57/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.2646\n",
      "Epoch 58/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.2537\n",
      "Epoch 59/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2465\n",
      "Epoch 60/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2409\n",
      "Epoch 61/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2338\n",
      "Epoch 62/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2278\n",
      "Epoch 63/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2297\n",
      "Epoch 64/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2243\n",
      "Epoch 65/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2144\n",
      "Epoch 66/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2060\n",
      "Epoch 67/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.2026\n",
      "Epoch 68/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.1980\n",
      "Epoch 69/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.1956\n",
      "Epoch 70/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.1879\n",
      "Epoch 71/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.1810\n",
      "Epoch 72/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.1719\n",
      "Epoch 73/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1679\n",
      "Epoch 74/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1556\n",
      "Epoch 75/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1560\n",
      "Epoch 76/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.1493\n",
      "Epoch 77/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.1436\n",
      "Epoch 78/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1380\n",
      "Epoch 79/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1324\n",
      "Epoch 80/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1232\n",
      "Epoch 81/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1157\n",
      "Epoch 82/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1128\n",
      "Epoch 83/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.1089\n",
      "Epoch 84/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0965\n",
      "Epoch 85/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0937\n",
      "Epoch 86/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0869\n",
      "Epoch 87/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0808\n",
      "Epoch 88/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0739\n",
      "Epoch 89/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0670\n",
      "Epoch 90/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0694\n",
      "Epoch 91/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0597\n",
      "Epoch 92/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0486\n",
      "Epoch 93/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0496\n",
      "Epoch 94/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0380\n",
      "Epoch 95/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0328\n",
      "Epoch 96/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0289\n",
      "Epoch 97/100\n",
      "4096/4096 [==============================] - 33s 8ms/sample - loss: 7.0251\n",
      "Epoch 98/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0209\n",
      "Epoch 99/100\n",
      "4096/4096 [==============================] - 32s 8ms/sample - loss: 7.0125\n",
      "Epoch 100/100\n",
      "4096/4096 [==============================] - 31s 8ms/sample - loss: 7.0076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe089b70290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "#lstm.fit(train_structs.reshape((train_structs.shape[0], 1, train_structs.shape[1])), target_structs, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f0a0794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to file\n",
    "lstm.save('../checkpoints/event_structure_based_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model from file\n",
    "lstm = load_model('../checkpoints/event_structure_based_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9ecf5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (1, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6225313f9e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Generate chords and durations using 500 rounds of prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnew_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictChords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_structs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnew_structs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minitial_structs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_structs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-6225313f9e6d>\u001b[0m in \u001b[0;36mpredictChords\u001b[0;34m(struct_sequence)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_structs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredictChords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredicted_structs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_structs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (1, 64)"
     ]
    }
   ],
   "source": [
    "# Start by inputing the first event structure from the training data\n",
    "initial_structs = np.expand_dims(train_structs[0,:].copy(), 0)\n",
    "print(initial_structs.shape)\n",
    "\n",
    "# Predict the next event structure\n",
    "def predict_structs(struct_sequence):\n",
    "    predicted_structs= lstm.predict(struct_sequence)\n",
    "    return np.argmax(predicted_structs)\n",
    "\n",
    "# Define empty lists for generated event structures\n",
    "new_structs = []\n",
    "\n",
    "# Generate event structures using 500 rounds of prediction\n",
    "for j in range(500):\n",
    "    new_struct = predict_structs(initial_structs)\n",
    "    new_structs.append(new_struct)\n",
    "    initial_structs[0][:-1] = initial_structs[0][1:]\n",
    "    initial_structs[0][-1] = new_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f0fecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5269a723",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac923e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_structs[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_events = np.asarray(sum(new_structs,()), dtype=object)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
